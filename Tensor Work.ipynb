{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root = \"data\" , \n",
    "    train = True,\n",
    "    download= True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root = \"data\" , \n",
    "    train=False,\n",
    "    download = True,\n",
    "    transform= ToTensor()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
       "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
       "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
       "           0.0157, 0.0000, 0.0000, 0.0118],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
       "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0471, 0.0392, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
       "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
       "           0.3020, 0.5098, 0.2824, 0.0588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
       "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
       "           0.5529, 0.3451, 0.6745, 0.2588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
       "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
       "           0.4824, 0.7686, 0.8980, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
       "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
       "           0.8745, 0.9608, 0.6784, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
       "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
       "           0.8627, 0.9529, 0.7922, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
       "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
       "           0.8863, 0.7725, 0.8196, 0.2039],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
       "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
       "           0.9608, 0.4667, 0.6549, 0.2196],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
       "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
       "           0.8510, 0.8196, 0.3608, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
       "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
       "           0.8549, 1.0000, 0.3020, 0.0000],\n",
       "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
       "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
       "           0.8784, 0.9569, 0.6235, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
       "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
       "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
       "           0.9137, 0.9333, 0.8431, 0.0000],\n",
       "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
       "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
       "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
       "           0.8627, 0.9098, 0.9647, 0.0000],\n",
       "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
       "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
       "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
       "           0.8706, 0.8941, 0.8824, 0.0000],\n",
       "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
       "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
       "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
       "           0.8745, 0.8784, 0.8980, 0.1137],\n",
       "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
       "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
       "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
       "           0.8627, 0.8667, 0.9020, 0.2627],\n",
       "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
       "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
       "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
       "           0.7098, 0.8039, 0.8078, 0.4510],\n",
       "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
       "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
       "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
       "           0.6549, 0.6941, 0.8235, 0.3608],\n",
       "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
       "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
       "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
       "           0.7529, 0.8471, 0.6667, 0.0000],\n",
       "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
       "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
       "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
       "           0.3882, 0.2275, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
       "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 9)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "from torchvision.io import read_image \n",
    "class CustomImageDataset(Dataset): \n",
    "    def __init__ (self, annotations_file, img_dir, transform = None, target_transform = None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__ (self):\n",
    "        return len(self.img_labels)\n",
    "    def __getitem__ (self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0 ])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size = 64, shuffle = True)\n",
    "test_dataloader = DataLoader(test_data, batch_size = 64, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
       "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
       "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
       "           0.0157, 0.0000, 0.0000, 0.0118],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
       "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0471, 0.0392, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
       "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
       "           0.3020, 0.5098, 0.2824, 0.0588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
       "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
       "           0.5529, 0.3451, 0.6745, 0.2588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
       "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
       "           0.4824, 0.7686, 0.8980, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
       "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
       "           0.8745, 0.9608, 0.6784, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
       "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
       "           0.8627, 0.9529, 0.7922, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
       "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
       "           0.8863, 0.7725, 0.8196, 0.2039],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
       "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
       "           0.9608, 0.4667, 0.6549, 0.2196],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
       "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
       "           0.8510, 0.8196, 0.3608, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
       "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
       "           0.8549, 1.0000, 0.3020, 0.0000],\n",
       "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
       "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
       "           0.8784, 0.9569, 0.6235, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
       "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
       "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
       "           0.9137, 0.9333, 0.8431, 0.0000],\n",
       "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
       "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
       "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
       "           0.8627, 0.9098, 0.9647, 0.0000],\n",
       "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
       "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
       "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
       "           0.8706, 0.8941, 0.8824, 0.0000],\n",
       "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
       "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
       "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
       "           0.8745, 0.8784, 0.8980, 0.1137],\n",
       "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
       "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
       "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
       "           0.8627, 0.8667, 0.9020, 0.2627],\n",
       "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
       "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
       "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
       "           0.7098, 0.8039, 0.8078, 0.4510],\n",
       "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
       "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
       "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
       "           0.6549, 0.6941, 0.8235, 0.3608],\n",
       "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
       "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
       "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
       "           0.7529, 0.8471, 0.6667, 0.0000],\n",
       "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
       "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
       "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
       "           0.3882, 0.2275, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
       "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]))"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ToTesnro conerts PIL Image or NumPy ndarray into a float Tensor\n",
    "#Lambda function turns the interger into a one-hot encoded tensor\n",
    "\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "ds = datasets.FashionMNIST(\n",
    "    root = \"data\" , \n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = ToTensor(),\n",
    "    target_transform = Lambda(lambda y : torch.zeros(10, dtype = torch.float).scatter_(0, torch.tensor(y), value = 1))\n",
    "\n",
    ")\n",
    "next(iter(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_transform = Lambda(lambda y: torch.zeros(\n",
    "    10, dtype = torch.float).scatter_(dim = 0, index = torch.tensor(y) , value =1)\n",
    ")\n",
    "#Transforms our labels, we have 10 labels, scattering the index given by the label y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neural network is a modeule itself that consists of other modules, referred to as layers. This nested structure allows for building and managing architectures easily in PyTorch. PyTorch utilizes the torch.nn namepsace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "from torch import nn \n",
    "from torchvision import datasets, transforms\n",
    "#Check if we can use GPU or MPS\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ") \n",
    "print(f\"Using {device} device\")\n",
    "#It implements the same function as CPU tensors, but they utilize GPUs for computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flattens a contiguous range of dims into a tensor.\n",
    "class NeuralNetwork (nn.Module):\n",
    "    def __init__(self) : \n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,10),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "            x = self.flatten(x)\n",
    "            logits = self.linear_relu_stack(x)\n",
    "            return logits\n",
    "#nn.Flatten() flattens the image tensor from a 3D shape (batch_size, height, width) \n",
    "#to a 2D Shape (batch_size, height*width)\n",
    "#flatten is which allows to flatten the dimensions, as it flattens all dimensiosn excepth the batch dim (0th dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: tensor([8], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#Do not call model forward directly\n",
    "#We pass the input data to excecute forward\n",
    "X= torch.rand(1,28,28 , device= device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted Class: {y_pred}\")\n",
    "#SoftMax coverts logits to probabilities, summing over classes to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "#Breakdown of what happens with a minibatch of 3 images, size 28*28\n",
    "input_image = torch.rand(3,28,28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())\n",
    "#Flattened the dim while keeping the batch size, initializing the flatten layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0075, -0.2575,  0.2965,  0.0143, -0.4572,  0.0835,  0.1404,  0.2619,\n",
       "          0.3278, -0.1131,  0.0014, -0.0566, -0.5270,  0.5623,  0.6280,  0.4157,\n",
       "          0.3524,  0.0567,  0.0415,  0.1498],\n",
       "        [-0.0351, -0.4016,  0.5759,  0.1131, -0.5986,  0.1360,  0.4346,  0.4368,\n",
       "          0.2758, -0.0493,  0.2434, -0.1600, -0.4079, -0.0485,  0.4996,  0.1867,\n",
       "          0.1355, -0.0450, -0.3072,  0.0340],\n",
       "        [-0.1317, -0.4163,  0.6880,  0.0994, -0.2862,  0.1617,  0.1620,  0.1101,\n",
       "         -0.0931,  0.0779,  0.1960, -0.1799, -0.3293,  0.1712,  0.8482,  0.4043,\n",
       "          0.2336,  0.4055,  0.0205, -0.1763]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will now work on the linear layer\n",
    "layer1 = nn.Linear(in_features=28*28, out_features = 20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())\n",
    "hidden1\n",
    "#Linear transformation on the input using the stored weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[ 0.0075, -0.2575,  0.2965,  0.0143, -0.4572,  0.0835,  0.1404,  0.2619,\n",
      "          0.3278, -0.1131,  0.0014, -0.0566, -0.5270,  0.5623,  0.6280,  0.4157,\n",
      "          0.3524,  0.0567,  0.0415,  0.1498],\n",
      "        [-0.0351, -0.4016,  0.5759,  0.1131, -0.5986,  0.1360,  0.4346,  0.4368,\n",
      "          0.2758, -0.0493,  0.2434, -0.1600, -0.4079, -0.0485,  0.4996,  0.1867,\n",
      "          0.1355, -0.0450, -0.3072,  0.0340],\n",
      "        [-0.1317, -0.4163,  0.6880,  0.0994, -0.2862,  0.1617,  0.1620,  0.1101,\n",
      "         -0.0931,  0.0779,  0.1960, -0.1799, -0.3293,  0.1712,  0.8482,  0.4043,\n",
      "          0.2336,  0.4055,  0.0205, -0.1763]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.0075, 0.0000, 0.2965, 0.0143, 0.0000, 0.0835, 0.1404, 0.2619, 0.3278,\n",
      "         0.0000, 0.0014, 0.0000, 0.0000, 0.5623, 0.6280, 0.4157, 0.3524, 0.0567,\n",
      "         0.0415, 0.1498],\n",
      "        [0.0000, 0.0000, 0.5759, 0.1131, 0.0000, 0.1360, 0.4346, 0.4368, 0.2758,\n",
      "         0.0000, 0.2434, 0.0000, 0.0000, 0.0000, 0.4996, 0.1867, 0.1355, 0.0000,\n",
      "         0.0000, 0.0340],\n",
      "        [0.0000, 0.0000, 0.6880, 0.0994, 0.0000, 0.1617, 0.1620, 0.1101, 0.0000,\n",
      "         0.0779, 0.1960, 0.0000, 0.0000, 0.1712, 0.8482, 0.4043, 0.2336, 0.4055,\n",
      "         0.0205, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "relu = nn.ReLU()\n",
    "hidden1 = relu(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn sequential is an ordered container of modules\n",
    "#we define the order of the modules for the data to pass through\n",
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20,10)\n",
    " )\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)\n",
    "#logits is the raw unnormalized scores a NN produces from its last linear layer\n",
    "#before any activation funct is applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax value:  tensor([[0.0943, 0.1197, 0.0966, 0.1037, 0.0844, 0.1139, 0.0654, 0.1229, 0.0954,\n",
      "         0.1036],\n",
      "        [0.1024, 0.1209, 0.0929, 0.1063, 0.0742, 0.1091, 0.0730, 0.1252, 0.0945,\n",
      "         0.1013],\n",
      "        [0.0965, 0.1295, 0.0914, 0.1086, 0.0748, 0.1248, 0.0668, 0.1171, 0.0925,\n",
      "         0.0980]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)\n",
    "#Converting classes to probabilities as said above\n",
    "#Dim indicates the dim along which the values must sum to 1\n",
    "print(f\"Softmax value:  {pred_probab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ") \n",
      "\n",
      "\n",
      "Layer linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values: tensor([[ 0.0078,  0.0321,  0.0265,  ...,  0.0045, -0.0205, -0.0034],\n",
      "        [ 0.0169,  0.0074,  0.0346,  ..., -0.0261,  0.0263,  0.0210]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer linear_relu_stack.0.bias | Size: torch.Size([512]) | Values: tensor([-0.0354, -0.0200], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values: tensor([[-0.0050, -0.0040,  0.0253,  ...,  0.0110,  0.0402, -0.0282],\n",
      "        [ 0.0022, -0.0228,  0.0306,  ..., -0.0143, -0.0078, -0.0069]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer linear_relu_stack.2.bias | Size: torch.Size([512]) | Values: tensor([-0.0439,  0.0378], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values: tensor([[ 0.0262,  0.0331, -0.0040,  ...,  0.0137, -0.0040, -0.0426],\n",
      "        [ 0.0056, -0.0208, -0.0074,  ...,  0.0002,  0.0391, -0.0106]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer linear_relu_stack.4.bias | Size: torch.Size([10]) | Values: tensor([-0.0104, -0.0005], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Size | Preview of values \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Layers can be parametrized, i.e. has biases and weights\n",
    "#Subclassing nn.Module tracks and makes parameteres accessible\n",
    "\n",
    "print(f\"Model structure: {model} \\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer {name} | Size: {param.size()} | Values: {param[:2]} \\n\")\n",
    "print(f\"Size | Preview of values \\n\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick rundown here on understanding tensor shapes, a tensor with shape (3,4,5) has 3 slices or blocks, each block having 4 rows, and each row has 5 columns**\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "**So in our example we have a tensor with a shape of (10 , 512) meaning we have  atensor with 10 blocks, each block having 512 rows**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Now we'll look at the math and how back propagation works**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple one-layer network\n",
    "\n",
    "x = torch.ones(5) #input tensor\n",
    "y = torch.zeros(3) #expected output\n",
    "w = torch.randn(5,3, requires_grad=True)\n",
    "b= torch.randn(3, requires_grad=True)\n",
    "z=torch.matmul(x,w) + b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z,y)\n",
    "#w,b are parameters to optimize, to do this we will need to be able to computer the gradients of loss function\n",
    "#with respect to w,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f5f2f1; padding: 10px; border-radius: 5px;\">\n",
    "\n",
    "    ![alt text](comp-graph.png \"This is the computational graph\")\n",
    "\n",
    "</div>\n",
    "\n",
    "I'll come back to make this work eventually with HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient function for z = <AddBackward0 object at 0x0000020C31073940>\n",
      "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x0000020C31082DA0>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Gradient function for z = {z.grad_fn}\")\n",
    "print(f\"Gradient function for loss = {loss.grad_fn}\")\n",
    "#Grad_Fn is the stored reference to the backwards propagation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0740, 0.1286, 0.2901],\n",
      "        [0.0740, 0.1286, 0.2901],\n",
      "        [0.0740, 0.1286, 0.2901],\n",
      "        [0.0740, 0.1286, 0.2901],\n",
      "        [0.0740, 0.1286, 0.2901]])\n",
      "tensor([0.0740, 0.1286, 0.2901])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)\n",
    "#Computing the derivatives of our loss function with respect to the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#To disable gradient tracking, i.e. when the model is trained and we just want to input some data\n",
    "#We can stop tracking computations by using detach on the tensor\n",
    "z = torch.matmul(x,w ) + b\n",
    "z_det = z.detach()\n",
    "print(z_det.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a model and data its time to train, validate and test our model by optimizing its parameters on our data. \n",
    "Training a model is an iterative process; in each iteration the model makes a guess about the output, calculates the error in its guess (loss), collects the derivatives of the error with respect to its parameters (as we saw in the previous section), \n",
    "#and optimizes these parameters using gradient descent.\n",
    "\n",
    "---\n",
    "**Number of Epochs** : Number of times we iterate over the dataset \n",
    "\n",
    "\n",
    "**Batch size** : Number of data samples propagates through the network before our parameters are updated\n",
    "\n",
    "\n",
    "**Learning rate** : How much to update our models parameters after each epoch. Largue values may result in unpredictable behavior during training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize our loss function\n",
    "loss_fin = nn.CrossEntropyLoss()\n",
    "#Remember loss function measures the degree of dissimilarity of the result to the target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we work on optimizing our processes, by registering the param to be trained and the learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters() , lr = learning_rate)\n",
    "#This will zero each gradient at iteration, backpropogate the prediction loss, and adjust the param collected in a backwards pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    #Set the model to train mode\n",
    "    #Unecessary but it's a good practice\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Move data and labels to the device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{len(dataloader.dataset):>5d}]\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    #Set the model to eval mode\n",
    "    #Unecessary but added for practices\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    #Evaluating with no grad ensures no gradients are computed\n",
    "    #Import in test mode\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            # Move data and labels to the device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # Compute prediction and loss\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= len(dataloader.dataset)\n",
    "    correct /= len(dataloader.dataset)\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.317947  [    0/60000]\n",
      "loss: 2.294726  [ 6400/60000]\n",
      "loss: 2.274403  [12800/60000]\n",
      "loss: 2.246629  [19200/60000]\n",
      "loss: 2.254611  [25600/60000]\n",
      "loss: 2.231626  [32000/60000]\n",
      "loss: 2.215369  [38400/60000]\n",
      "loss: 2.190771  [44800/60000]\n",
      "loss: 2.171211  [51200/60000]\n",
      "loss: 2.161926  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 47.4%, Avg loss: 0.033755 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.164245  [    0/60000]\n",
      "loss: 2.133226  [ 6400/60000]\n",
      "loss: 2.085636  [12800/60000]\n",
      "loss: 2.066140  [19200/60000]\n",
      "loss: 2.065338  [25600/60000]\n",
      "loss: 2.010467  [32000/60000]\n",
      "loss: 1.986340  [38400/60000]\n",
      "loss: 1.958118  [44800/60000]\n",
      "loss: 1.929355  [51200/60000]\n",
      "loss: 1.881523  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 51.6%, Avg loss: 0.029371 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.853181  [    0/60000]\n",
      "loss: 1.822091  [ 6400/60000]\n",
      "loss: 1.805695  [12800/60000]\n",
      "loss: 1.674962  [19200/60000]\n",
      "loss: 1.675149  [25600/60000]\n",
      "loss: 1.657928  [32000/60000]\n",
      "loss: 1.675790  [38400/60000]\n",
      "loss: 1.532670  [44800/60000]\n",
      "loss: 1.603688  [51200/60000]\n",
      "loss: 1.558446  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 58.7%, Avg loss: 0.023694 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.494638  [    0/60000]\n",
      "loss: 1.448000  [ 6400/60000]\n",
      "loss: 1.439504  [12800/60000]\n",
      "loss: 1.385654  [19200/60000]\n",
      "loss: 1.447632  [25600/60000]\n",
      "loss: 1.374621  [32000/60000]\n",
      "loss: 1.320960  [38400/60000]\n",
      "loss: 1.285149  [44800/60000]\n",
      "loss: 1.290601  [51200/60000]\n",
      "loss: 1.113050  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.019657 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.389973  [    0/60000]\n",
      "loss: 1.186204  [ 6400/60000]\n",
      "loss: 1.196611  [12800/60000]\n",
      "loss: 1.245837  [19200/60000]\n",
      "loss: 1.058707  [25600/60000]\n",
      "loss: 1.065987  [32000/60000]\n",
      "loss: 1.144189  [38400/60000]\n",
      "loss: 1.211634  [44800/60000]\n",
      "loss: 1.169218  [51200/60000]\n",
      "loss: 1.113828  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.2%, Avg loss: 0.017120 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.979918  [    0/60000]\n",
      "loss: 0.951333  [ 6400/60000]\n",
      "loss: 1.064775  [12800/60000]\n",
      "loss: 1.044702  [19200/60000]\n",
      "loss: 1.048607  [25600/60000]\n",
      "loss: 1.187467  [32000/60000]\n",
      "loss: 1.123447  [38400/60000]\n",
      "loss: 0.935495  [44800/60000]\n",
      "loss: 1.067568  [51200/60000]\n",
      "loss: 0.890165  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.6%, Avg loss: 0.015482 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.976262  [    0/60000]\n",
      "loss: 0.858802  [ 6400/60000]\n",
      "loss: 0.974493  [12800/60000]\n",
      "loss: 0.962479  [19200/60000]\n",
      "loss: 0.858185  [25600/60000]\n",
      "loss: 0.909941  [32000/60000]\n",
      "loss: 0.852810  [38400/60000]\n",
      "loss: 0.974172  [44800/60000]\n",
      "loss: 1.056586  [51200/60000]\n",
      "loss: 0.778751  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.5%, Avg loss: 0.014344 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.865567  [    0/60000]\n",
      "loss: 0.790692  [ 6400/60000]\n",
      "loss: 0.816146  [12800/60000]\n",
      "loss: 0.821850  [19200/60000]\n",
      "loss: 0.759461  [25600/60000]\n",
      "loss: 0.783834  [32000/60000]\n",
      "loss: 0.882393  [38400/60000]\n",
      "loss: 0.932534  [44800/60000]\n",
      "loss: 0.889497  [51200/60000]\n",
      "loss: 0.877136  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 0.013533 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.942530  [    0/60000]\n",
      "loss: 0.814186  [ 6400/60000]\n",
      "loss: 0.856451  [12800/60000]\n",
      "loss: 0.806801  [19200/60000]\n",
      "loss: 0.835369  [25600/60000]\n",
      "loss: 0.822060  [32000/60000]\n",
      "loss: 0.749577  [38400/60000]\n",
      "loss: 0.910760  [44800/60000]\n",
      "loss: 0.877260  [51200/60000]\n",
      "loss: 0.817281  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 0.012927 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.780665  [    0/60000]\n",
      "loss: 0.837218  [ 6400/60000]\n",
      "loss: 0.900318  [12800/60000]\n",
      "loss: 0.658597  [19200/60000]\n",
      "loss: 0.830867  [25600/60000]\n",
      "loss: 1.025494  [32000/60000]\n",
      "loss: 0.787176  [38400/60000]\n",
      "loss: 0.699009  [44800/60000]\n",
      "loss: 0.843704  [51200/60000]\n",
      "loss: 0.813601  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.3%, Avg loss: 0.012415 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\adenm/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "#PyTorch models store the learned parameters in state_dict\n",
    "#These can persist with torch.save\n",
    "import torchvision.models as models\n",
    "model = models.vgg16(weights = 'IMAGENET1K_V1')\n",
    "torch.save(model.state_dict() , 'model_weights.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To load this models weights\n",
    "model = models.vgg16()\n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "model.eval()\n",
    "#Do this right after loading the model weights\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
